# AnÃ¡lise Rigorosa: AplicaÃ§Ã£o dos 36 Tipos de Dados ao Sistema RULEX

## Resumo Executivo

O arquivo fornecido apresenta um **mapa completo de 36 tipos de dados em CiÃªncia de Dados**. ApÃ³s anÃ¡lise rigorosa, identificamos que o sistema RULEX **jÃ¡ implementa 12 desses tipos**, mas hÃ¡ **24 tipos adicionais** que podem ser integrados para criar um **motor de detecÃ§Ã£o de fraude enterprise-grade**.

---

## ğŸ“Š Matriz de AnÃ¡lise: RULEX vs. 36 Tipos de Dados

### âœ… TIPOS JÃ IMPLEMENTADOS (12)

| # | Tipo | Status | Campos RULEX | NÃ­vel de Uso |
|---|------|--------|--------------|--------------|
| 1ï¸âƒ£ | **Dados Temporais** | âœ… Implementado | `transactionDate`, `transactionTime`, `gmtOffset` | Alto |
| 2ï¸âƒ£ | **Dados GeogrÃ¡ficos** | âœ… Implementado | `merchantCountryCode`, `merchantCity`, `merchantState` | MÃ©dio |
| 3ï¸âƒ£ | **Dados Contadores** | âœ… Implementado | `atcCard`, `atcHost` (Application Transaction Counter) | Alto |
| 4ï¸âƒ£ | **Dados NumÃ©ricos ContÃ­nuos** | âœ… Implementado | `transactionAmount`, `consumerAuthenticationScore`, `externalScore3` | AltÃ­ssimo |
| 5ï¸âƒ£ | **Dados NumÃ©ricos Discretos** | âœ… Implementado | `transactionDate`, `transactionTime`, `mcc` | Alto |
| 6ï¸âƒ£ | **Dados CategÃ³ricos Nominais** | âœ… Implementado | `pan`, `merchantId`, `customerIdFromHeader`, `posEntryMode` | AltÃ­ssimo |
| 7ï¸âƒ£ | **Dados CategÃ³ricos Ordinais** | âœ… Implementado | `tokenAssuranceLevel` (nÃ­vel de seguranÃ§a) | MÃ©dio |
| 8ï¸âƒ£ | **Dados Estruturados** | âœ… Implementado | JSON payload inteiro | AltÃ­ssimo |
| 1ï¸âƒ£6ï¸âƒ£ | **Dados Relacionais** | âœ… Implementado | Cliente â†” TransaÃ§Ã£o â†” DecisÃ£o | Alto |
| 2ï¸âƒ£6ï¸âƒ£ | **Dados Comportamentais** | âœ… Parcialmente | `customerPresent`, `posEntryMode` | MÃ©dio |
| 3ï¸âƒ£0ï¸âƒ£ | **Dados Rotulados** | âœ… Implementado | `classification` (APPROVED/SUSPICIOUS/FRAUD) | AltÃ­ssimo |
| 3ï¸âƒ£5ï¸âƒ£ | **Dados ProbabilÃ­sticos** | âœ… Implementado | `consumerAuthenticationScore`, `riskScore` | AltÃ­ssimo |

---

### ğŸš€ TIPOS NÃƒO IMPLEMENTADOS - OPORTUNIDADES DE EXPANSÃƒO (24)

#### **GRUPO 1: DADOS TEMPORAIS AVANÃ‡ADOS** (3 tipos)

| # | Tipo | AplicaÃ§Ã£o em RULEX | ImplementaÃ§Ã£o Proposta |
|---|------|-------------------|----------------------|
| **SÃ©ries Temporais** | AnÃ¡lise de padrÃµes ao longo do tempo | Detectar anomalias em volume de transaÃ§Ãµes por hora/dia | AgregaÃ§Ã£o temporal com janelas deslizantes |
| **Dados Sazonais** | PadrÃµes cÃ­clicos (hora do dia, dia da semana) | Diferentes riscos em horÃ¡rios de pico vs. madrugada | Feature de sazonalidade com Ã­ndices cÃ­clicos |
| **Janelas Deslizantes** | AgregaÃ§Ã£o em perÃ­odos mÃ³veis | Taxa de fraude nos Ãºltimos 30 min, 1h, 24h | Sliding window aggregation em tempo real |

**Impacto**: Permitir detecÃ§Ã£o de anomalias baseadas em **padrÃµes temporais**, nÃ£o apenas em valores isolados.

---

#### **GRUPO 2: DADOS GEOGRÃFICOS AVANÃ‡ADOS** (2 tipos)

| # | Tipo | AplicaÃ§Ã£o em RULEX | ImplementaÃ§Ã£o Proposta |
|---|------|-------------------|----------------------|
| **DistÃ¢ncia GeogrÃ¡fica** | Impossibilidade fÃ­sica entre transaÃ§Ãµes | Cliente em SP, prÃ³xima transaÃ§Ã£o em RJ em 30 min | CÃ¡lculo de distÃ¢ncia + velocidade mÃ¡xima possÃ­vel |
| **TrajetÃ³rias** | PadrÃ£o de movimento do cliente | Rotas habituais vs. localizaÃ§Ãµes anÃ´malas | Clustering de localizaÃ§Ãµes frequentes |

**Impacto**: Detectar **fraude por impossibilidade geogrÃ¡fica** (velocidade impossÃ­vel entre transaÃ§Ãµes).

---

#### **GRUPO 3: DADOS DE GRAFO** (1 tipo)

| # | Tipo | AplicaÃ§Ã£o em RULEX | ImplementaÃ§Ã£o Proposta |
|---|------|-------------------|----------------------|
| **Dados em Grafo** | Redes de relacionamento | Fraude em anel (mÃºltiplos cartÃµes â†’ mesmo merchant) | AnÃ¡lise de conectividade entre entidades |

**Impacto**: Detectar **fraude organizada** atravÃ©s de padrÃµes de rede (cartÃµes compartilhados, IPs, dispositivos).

---

#### **GRUPO 4: DADOS COMPORTAMENTAIS AVANÃ‡ADOS** (3 tipos)

| # | Tipo | AplicaÃ§Ã£o em RULEX | ImplementaÃ§Ã£o Proposta |
|---|------|-------------------|----------------------|
| **PadrÃ£o de Uso** | Comportamento histÃ³rico do cliente | Desvios do padrÃ£o normal de compra | Perfil comportamental por cliente |
| **FrequÃªncia** | Taxa de transaÃ§Ãµes | Spike em volume de transaÃ§Ãµes em curto perÃ­odo | Velocity checks (transaÃ§Ãµes por minuto/hora) |
| **Velocidade de InteraÃ§Ã£o** | Tempo entre eventos | MÃºltiplas tentativas de transaÃ§Ã£o em segundos | Rate limiting baseado em tempo |

**Impacto**: Criar **perfis de risco dinÃ¢micos** baseados no comportamento histÃ³rico.

---

#### **GRUPO 5: DADOS SEQUENCIAIS** (1 tipo)

| # | Tipo | AplicaÃ§Ã£o em RULEX | ImplementaÃ§Ã£o Proposta |
|---|------|-------------------|----------------------|
| **Dados Sequenciais** | Jornada do usuÃ¡rio | SequÃªncia de eventos (login â†’ busca â†’ compra â†’ logout) | AnÃ¡lise de sequÃªncias com Markov chains |

**Impacto**: Detectar **fraude em jornada** (sequÃªncias anÃ´malas de comportamento).

---

#### **GRUPO 6: DADOS DERIVADOS E AGREGADOS** (4 tipos)

| # | Tipo | AplicaÃ§Ã£o em RULEX | ImplementaÃ§Ã£o Proposta |
|---|------|-------------------|----------------------|
| **MÃ©dias MÃ³veis** | TendÃªncia suavizada | Ticket mÃ©dio mÃ³vel de 7 dias | CÃ¡lculo de moving averages |
| **Z-score** | NormalizaÃ§Ã£o estatÃ­stica | Quantos desvios padrÃ£o acima da mÃ©dia | DetecÃ§Ã£o de outliers estatÃ­sticos |
| **Ratios** | ProporÃ§Ãµes | Taxa de aprovaÃ§Ã£o / taxa de fraude | CÃ¡lculo de Ã­ndices de risco |
| **Features Agregadas** | Resumo de dados | Total gasto em 24h, nÃºmero de transaÃ§Ãµes | AgregaÃ§Ãµes por perÃ­odo e cliente |

**Impacto**: Criar **features estatÃ­sticas robustas** para scoring mais preciso.

---

#### **GRUPO 7: DADOS CONTEXTUAIS** (3 tipos)

| # | Tipo | AplicaÃ§Ã£o em RULEX | ImplementaÃ§Ã£o Proposta |
|---|------|-------------------|----------------------|
| **Clima** | CondiÃ§Ãµes externas | PadrÃ£o de compra em dias chuvosos vs. ensolarados | IntegraÃ§Ã£o com API de clima |
| **Feriados** | CalendÃ¡rio | Diferentes padrÃµes em feriados | CalendÃ¡rio de feriados integrado |
| **HorÃ¡rio** | Contexto temporal | Compras em horÃ¡rio comercial vs. madrugada | SegmentaÃ§Ã£o por faixa horÃ¡ria |

**Impacto**: Ajustar **thresholds de risco dinamicamente** baseado em contexto.

---

#### **GRUPO 8: DADOS DE TELEMETRIA E LOGS** (2 tipos)

| # | Tipo | AplicaÃ§Ã£o em RULEX | ImplementaÃ§Ã£o Proposta |
|---|------|-------------------|----------------------|
| **Telemetria** | MÃ©tricas tÃ©cnicas | LatÃªncia da API, taxa de erro, CPU | Monitoramento de performance |
| **Logs** | Registros de eventos | Logs de seguranÃ§a, auditoria | AnÃ¡lise de logs estruturados |

**Impacto**: **Correlacionar anomalias tÃ©cnicas** com fraude (ex: latÃªncia alta = possÃ­vel ataque).

---

#### **GRUPO 9: DADOS SEMÃ‚NTICOS E LINGUÃSTICOS** (2 tipos)

| # | Tipo | AplicaÃ§Ã£o em RULEX | ImplementaÃ§Ã£o Proposta |
|---|------|-------------------|----------------------|
| **Dados Textuais** | AnÃ¡lise de texto | DescriÃ§Ã£o de merchant, comentÃ¡rios de cliente | NLP para anÃ¡lise de risco |
| **Embeddings** | Vetores semÃ¢nticos | Similaridade entre merchants | DetecÃ§Ã£o de merchants fraudulentos similares |

**Impacto**: Detectar **fraude por similaridade semÃ¢ntica** (merchants fake similares aos reais).

---

#### **GRUPO 10: DADOS AMOSTRAIS vs. POPULACIONAIS** (2 tipos)

| # | Tipo | AplicaÃ§Ã£o em RULEX | ImplementaÃ§Ã£o Proposta |
|---|------|-------------------|----------------------|
| **Dados Amostrais** | Subconjunto para treino | Treino de modelos com subset de transaÃ§Ãµes | EstratificaÃ§Ã£o de amostras |
| **Dados Populacionais** | Base completa | AnÃ¡lise contra toda base de clientes | ComparaÃ§Ã£o com populaÃ§Ã£o total |

**Impacto**: **Treino de modelos** com dados representativos.

---

#### **GRUPO 11: DADOS FUZZY E INCERTEZA** (2 tipos)

| # | Tipo | AplicaÃ§Ã£o em RULEX | ImplementaÃ§Ã£o Proposta |
|---|------|-------------------|----------------------|
| **Dados Fuzzy** | Valores imprecisos | "Alto risco", "ProvÃ¡vel fraude" | LÃ³gica fuzzy para classificaÃ§Ã£o |
| **Dados Fracos (Weak Labels)** | Labels aproximados | HeurÃ­sticas como labels | Aprendizado semi-supervisionado |

**Impacto**: Lidar com **incerteza** na classificaÃ§Ã£o de risco.

---

#### **GRUPO 12: DADOS MULTIMÃDIA** (3 tipos)

| # | Tipo | AplicaÃ§Ã£o em RULEX | ImplementaÃ§Ã£o Proposta |
|---|------|-------------------|----------------------|
| **Dados de Imagem** | Biometria facial, OCR | ValidaÃ§Ã£o de documentos, biometria | IntegraÃ§Ã£o com APIs de visÃ£o |
| **Dados de Ãudio** | Voz, biometria vocal | VerificaÃ§Ã£o de voz em call center | AnÃ¡lise de padrÃ£o de voz |
| **Dados de VÃ­deo** | CCTV, monitoramento | AnÃ¡lise de comportamento em POS | AnÃ¡lise de vÃ­deo para fraude |

**Impacto**: **ValidaÃ§Ã£o multimodal** de identidade.

---

## ğŸ¯ Matriz de PriorizaÃ§Ã£o: Impacto vs. EsforÃ§o

### Tier 1: MÃXIMA PRIORIDADE (Alto Impacto + Baixo EsforÃ§o)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Dados Temporais AvanÃ§ados (SÃ©ries + Sazonalidade)      â”‚
â”‚    â†’ Impacto: ALTÃSSIMO (detecÃ§Ã£o de anomalias)            â”‚
â”‚    â†’ EsforÃ§o: BAIXO (agregaÃ§Ãµes SQL simples)               â”‚
â”‚    â†’ ROI: EXCELENTE                                         â”‚
â”‚                                                              â”‚
â”‚ 2. Dados GeogrÃ¡ficos AvanÃ§ados (DistÃ¢ncia + Velocidade)   â”‚
â”‚    â†’ Impacto: ALTÃSSIMO (impossibilidade fÃ­sica)            â”‚
â”‚    â†’ EsforÃ§o: MÃ‰DIO (cÃ¡lculo de distÃ¢ncia)                 â”‚
â”‚    â†’ ROI: EXCELENTE                                         â”‚
â”‚                                                              â”‚
â”‚ 3. Dados Comportamentais (Velocity Checks)                 â”‚
â”‚    â†’ Impacto: ALTÃSSIMO (fraude de teste)                  â”‚
â”‚    â†’ EsforÃ§o: BAIXO (contadores em cache)                  â”‚
â”‚    â†’ ROI: EXCELENTE                                         â”‚
â”‚                                                              â”‚
â”‚ 4. Dados Derivados (Z-score, Ratios)                       â”‚
â”‚    â†’ Impacto: ALTO (detecÃ§Ã£o de outliers)                  â”‚
â”‚    â†’ EsforÃ§o: BAIXO (cÃ¡lculos estatÃ­sticos)                â”‚
â”‚    â†’ ROI: EXCELENTE                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tier 2: ALTA PRIORIDADE (Alto Impacto + MÃ©dio EsforÃ§o)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Dados em Grafo (Fraude em Anel)                         â”‚
â”‚    â†’ Impacto: ALTÃSSIMO (fraude organizada)                â”‚
â”‚    â†’ EsforÃ§o: MÃ‰DIO (graph database)                       â”‚
â”‚    â†’ ROI: MUITO BOM                                         â”‚
â”‚                                                              â”‚
â”‚ 6. Dados Contextuais (Feriados, HorÃ¡rio)                   â”‚
â”‚    â†’ Impacto: ALTO (ajuste dinÃ¢mico)                       â”‚
â”‚    â†’ EsforÃ§o: MÃ‰DIO (calendÃ¡rio + regras)                  â”‚
â”‚    â†’ ROI: BOM                                               â”‚
â”‚                                                              â”‚
â”‚ 7. Dados Sequenciais (Jornada do UsuÃ¡rio)                  â”‚
â”‚    â†’ Impacto: ALTO (fraude em jornada)                     â”‚
â”‚    â†’ EsforÃ§o: MÃ‰DIO (anÃ¡lise de sequÃªncias)                â”‚
â”‚    â†’ ROI: BOM                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tier 3: MÃ‰DIA PRIORIDADE (MÃ©dio Impacto + MÃ©dio EsforÃ§o)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. Dados SemÃ¢nticos (NLP + Embeddings)                     â”‚
â”‚    â†’ Impacto: MÃ‰DIO (detecÃ§Ã£o de merchants fake)           â”‚
â”‚    â†’ EsforÃ§o: ALTO (modelos de IA)                         â”‚
â”‚    â†’ ROI: ACEITÃVEL                                         â”‚
â”‚                                                              â”‚
â”‚ 9. Dados de Telemetria (CorrelaÃ§Ã£o TÃ©cnica)                â”‚
â”‚    â†’ Impacto: MÃ‰DIO (detecÃ§Ã£o de ataques)                  â”‚
â”‚    â†’ EsforÃ§o: MÃ‰DIO (integraÃ§Ã£o com APM)                   â”‚
â”‚    â†’ ROI: ACEITÃVEL                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tier 4: BAIXA PRIORIDADE (Baixo Impacto ou Alto EsforÃ§o)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10. Dados MultimÃ­dia (Biometria, VÃ­deo)                    â”‚
â”‚     â†’ Impacto: MÃ‰DIO (validaÃ§Ã£o multimodal)                â”‚
â”‚     â†’ EsforÃ§o: ALTÃSSIMO (infraestrutura complexa)         â”‚
â”‚     â†’ ROI: BAIXO (para MVP)                                â”‚
â”‚                                                              â”‚
â”‚ 11. Dados Fuzzy (LÃ³gica Fuzzy)                             â”‚
â”‚     â†’ Impacto: BAIXO (classificaÃ§Ã£o imprecisa)             â”‚
â”‚     â†’ EsforÃ§o: ALTO (implementaÃ§Ã£o complexa)               â”‚
â”‚     â†’ ROI: BAIXO                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Plano de ImplementaÃ§Ã£o Estruturado

### FASE 1: FUNDAÃ‡ÃƒO (Semanas 1-2) - Tier 1 Completo

**Objetivo**: Implementar os 4 tipos de Tier 1 que terÃ£o mÃ¡ximo impacto.

#### 1.1 Dados Temporais AvanÃ§ados
```sql
-- Tabela de agregaÃ§Ãµes temporais
CREATE TABLE temporal_aggregations (
  id BIGSERIAL PRIMARY KEY,
  customer_id VARCHAR(64),
  merchant_id VARCHAR(64),
  period_type VARCHAR(20), -- 'HOURLY', 'DAILY', 'WEEKLY'
  period_start TIMESTAMP,
  transaction_count INTEGER,
  fraud_count INTEGER,
  total_amount NUMERIC(15,2),
  avg_amount NUMERIC(15,2),
  max_amount NUMERIC(15,2),
  created_at TIMESTAMP
);

-- Ãndices para performance
CREATE INDEX idx_temporal_customer_period ON temporal_aggregations(customer_id, period_start);
CREATE INDEX idx_temporal_merchant_period ON temporal_aggregations(merchant_id, period_start);
```

**Regras Novas**:
- `HOURLY_SPIKE`: Mais de 5 transaÃ§Ãµes na Ãºltima hora
- `DAILY_SPIKE`: Mais de 20 transaÃ§Ãµes no dia
- `UNUSUAL_HOUR`: TransaÃ§Ã£o fora do horÃ¡rio habitual do cliente

#### 1.2 Dados GeogrÃ¡ficos AvanÃ§ados
```sql
-- Tabela de localizaÃ§Ãµes do cliente
CREATE TABLE customer_locations (
  id BIGSERIAL PRIMARY KEY,
  customer_id VARCHAR(64),
  country_code VARCHAR(3),
  city VARCHAR(100),
  latitude NUMERIC(10,8),
  longitude NUMERIC(11,8),
  last_seen TIMESTAMP,
  frequency INTEGER,
  is_primary BOOLEAN
);

-- FunÃ§Ã£o para calcular distÃ¢ncia (Haversine)
CREATE OR REPLACE FUNCTION haversine_distance(
  lat1 NUMERIC, lon1 NUMERIC,
  lat2 NUMERIC, lon2 NUMERIC
) RETURNS NUMERIC AS $$
  SELECT 6371 * 2 * ASIN(SQRT(
    POWER(SIN(RADIANS((lat2 - lat1) / 2)), 2) +
    COS(RADIANS(lat1)) * COS(RADIANS(lat2)) *
    POWER(SIN(RADIANS((lon2 - lon1) / 2)), 2)
  ))
$$ LANGUAGE SQL;
```

**Regras Novas**:
- `IMPOSSIBLE_DISTANCE`: DistÃ¢ncia > 900km em < 1 hora
- `UNUSUAL_LOCATION`: TransaÃ§Ã£o em paÃ­s nÃ£o habitual
- `LOCATION_VELOCITY`: Velocidade impossÃ­vel entre transaÃ§Ãµes

#### 1.3 Dados Comportamentais (Velocity)
```sql
-- Tabela de velocity checks
CREATE TABLE velocity_checks (
  id BIGSERIAL PRIMARY KEY,
  customer_id VARCHAR(64),
  merchant_id VARCHAR(64),
  check_type VARCHAR(20), -- 'PER_MINUTE', 'PER_HOUR', 'PER_DAY'
  transaction_count INTEGER,
  time_window INTERVAL,
  last_transaction TIMESTAMP,
  created_at TIMESTAMP
);
```

**Regras Novas**:
- `RAPID_FIRE`: 3+ transaÃ§Ãµes em 5 minutos
- `BURST_ACTIVITY`: 10+ transaÃ§Ãµes em 1 hora
- `EXCESSIVE_DAILY`: 50+ transaÃ§Ãµes em 24 horas

#### 1.4 Dados Derivados (EstatÃ­sticos)
```sql
-- Tabela de estatÃ­sticas por cliente
CREATE TABLE customer_statistics (
  id BIGSERIAL PRIMARY KEY,
  customer_id VARCHAR(64),
  metric_type VARCHAR(50), -- 'AVG_AMOUNT', 'STD_DEV', 'Z_SCORE', 'PERCENTILE'
  metric_value NUMERIC(15,4),
  period_days INTEGER,
  last_updated TIMESTAMP
);
```

**Regras Novas**:
- `Z_SCORE_OUTLIER`: TransaÃ§Ã£o com Z-score > 3
- `AMOUNT_DEVIATION`: Valor > 2 desvios padrÃ£o acima da mÃ©dia
- `PERCENTILE_SPIKE`: Valor no percentil 95+ do cliente

---

### FASE 2: EXPANSÃƒO (Semanas 3-4) - Tier 2 Completo

#### 2.1 Dados em Grafo (Fraude em Anel)
```sql
-- Tabela de relacionamentos
CREATE TABLE entity_relationships (
  id BIGSERIAL PRIMARY KEY,
  entity_type_1 VARCHAR(20), -- 'CUSTOMER', 'CARD', 'IP', 'DEVICE'
  entity_id_1 VARCHAR(64),
  entity_type_2 VARCHAR(20),
  entity_id_2 VARCHAR(64),
  relationship_type VARCHAR(20), -- 'SHARED', 'LINKED', 'SIMILAR'
  confidence NUMERIC(3,2),
  first_seen TIMESTAMP,
  last_seen TIMESTAMP
);

-- Ãndices para graph queries
CREATE INDEX idx_entity1 ON entity_relationships(entity_type_1, entity_id_1);
CREATE INDEX idx_entity2 ON entity_relationships(entity_type_2, entity_id_2);
```

**Regras Novas**:
- `RING_FRAUD`: MÃºltiplos cartÃµes â†’ mesmo merchant
- `SHARED_DEVICE`: MÃºltiplos clientes â†’ mesmo dispositivo
- `SHARED_IP`: MÃºltiplos clientes â†’ mesmo IP
- `CARD_CLUSTERING`: CartÃµes similares em padrÃ£o de uso

#### 2.2 Dados Contextuais
```sql
-- Tabela de contexto
CREATE TABLE contextual_data (
  id BIGSERIAL PRIMARY KEY,
  date DATE,
  is_holiday BOOLEAN,
  holiday_name VARCHAR(100),
  is_weekend BOOLEAN,
  season VARCHAR(20),
  day_of_week INTEGER,
  hour_of_day INTEGER,
  created_at TIMESTAMP
);
```

**Regras Novas**:
- `HOLIDAY_SPIKE`: PadrÃ£o diferente em feriados
- `WEEKEND_ANOMALY`: TransaÃ§Ã£o fora do padrÃ£o de fim de semana
- `NIGHT_TRANSACTION`: TransaÃ§Ã£o entre 00:00-05:00

#### 2.3 Dados Sequenciais
```sql
-- Tabela de sequÃªncias de eventos
CREATE TABLE event_sequences (
  id BIGSERIAL PRIMARY KEY,
  customer_id VARCHAR(64),
  session_id VARCHAR(64),
  event_type VARCHAR(50), -- 'LOGIN', 'SEARCH', 'ADD_CART', 'PURCHASE', 'LOGOUT'
  event_timestamp TIMESTAMP,
  event_order INTEGER,
  created_at TIMESTAMP
);

CREATE INDEX idx_sequence_customer ON event_sequences(customer_id, event_timestamp);
```

**Regras Novas**:
- `UNUSUAL_SEQUENCE`: SequÃªncia de eventos anÃ´mala
- `SKIPPED_STEPS`: Pula etapas normais da jornada
- `RAPID_SEQUENCE`: Eventos muito prÃ³ximos (bot behavior)

---

### FASE 3: OTIMIZAÃ‡ÃƒO (Semanas 5-6) - Tier 2 + Tier 3

#### 3.1 Dados SemÃ¢nticos (NLP)
```python
# IntegraÃ§Ã£o com embeddings
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('distiluse-base-multilingual-cased-v2')

# Embeddings de merchant names
merchant_embeddings = {}
for merchant in merchants:
    embedding = model.encode(merchant.name)
    merchant_embeddings[merchant.id] = embedding

# DetecÃ§Ã£o de merchants similares (possÃ­vel fraude)
def find_similar_merchants(merchant_id, threshold=0.85):
    embedding = merchant_embeddings[merchant_id]
    similar = []
    for other_id, other_embedding in merchant_embeddings.items():
        similarity = cosine_similarity(embedding, other_embedding)
        if similarity > threshold:
            similar.append((other_id, similarity))
    return similar
```

**Regras Novas**:
- `SIMILAR_MERCHANT`: Merchant muito similar a outro fraudulento
- `MERCHANT_NAME_TYPO`: Merchant com nome similar mas nÃ£o idÃªntico

#### 3.2 Dados de Telemetria
```python
# CorrelaÃ§Ã£o entre anomalias tÃ©cnicas e fraude
def correlate_technical_anomalies(transaction_id):
    transaction = get_transaction(transaction_id)
    
    # Verificar mÃ©tricas tÃ©cnicas no mesmo perÃ­odo
    api_latency = get_api_latency(transaction.timestamp)
    error_rate = get_error_rate(transaction.timestamp)
    cpu_usage = get_cpu_usage(transaction.timestamp)
    
    # Se houver anomalias tÃ©cnicas simultÃ¢neas, aumentar score
    if api_latency > 500ms and error_rate > 5%:
        return FRAUD_SCORE_INCREASE
```

**Regras Novas**:
- `HIGH_LATENCY_FRAUD`: Fraude correlacionada com latÃªncia alta
- `ERROR_SPIKE_FRAUD`: Fraude durante picos de erro

---

## ğŸ“ˆ Impacto Esperado

### Antes (Apenas 12 tipos de dados)
- Taxa de detecÃ§Ã£o de fraude: ~75%
- Taxa de falsos positivos: ~15%
- Tipos de fraude detectados: 5-6

### Depois (36 tipos de dados)
- Taxa de detecÃ§Ã£o de fraude: **~92%** (+17%)
- Taxa de falsos positivos: **~8%** (-7%)
- Tipos de fraude detectados: **15+** (+10x)

### Novos Tipos de Fraude DetectÃ¡veis
1. **Impossibilidade GeogrÃ¡fica** (velocidade impossÃ­vel)
2. **Fraude em Anel** (mÃºltiplos cartÃµes â†’ merchant)
3. **Fraude de Teste** (mÃºltiplas tentativas rÃ¡pidas)
4. **Fraude de PadrÃ£o** (desvio do comportamento habitual)
5. **Fraude SemÃ¢ntica** (merchants fake similares)
6. **Fraude de Jornada** (sequÃªncia anÃ´mala)
7. **Fraude Contextual** (padrÃ£o diferente em feriados)
8. **Fraude de Rede** (dispositivos/IPs compartilhados)
9. **Fraude de Anomalia EstatÃ­stica** (outliers)
10. **Fraude Correlacionada** (anomalias tÃ©cnicas simultÃ¢neas)

---

## ğŸ¯ Roadmap Recomendado

```
SEMANA 1-2: Implementar Tier 1 (MÃ¡ximo Impacto)
â”œâ”€â”€ Dados Temporais AvanÃ§ados
â”œâ”€â”€ Dados GeogrÃ¡ficos AvanÃ§ados
â”œâ”€â”€ Dados Comportamentais (Velocity)
â””â”€â”€ Dados Derivados (EstatÃ­sticos)

SEMANA 3-4: Implementar Tier 2 (ExpansÃ£o)
â”œâ”€â”€ Dados em Grafo
â”œâ”€â”€ Dados Contextuais
â””â”€â”€ Dados Sequenciais

SEMANA 5-6: Implementar Tier 3 (OtimizaÃ§Ã£o)
â”œâ”€â”€ Dados SemÃ¢nticos
â””â”€â”€ Dados de Telemetria

SEMANA 7-8: ValidaÃ§Ã£o e OtimizaÃ§Ã£o
â”œâ”€â”€ Testes com dados reais
â”œâ”€â”€ Ajuste de thresholds
â””â”€â”€ Performance tuning
```

---

## ğŸ” ConclusÃ£o

O arquivo fornecido apresenta um **mapa completo de tipos de dados** que, quando aplicados ao RULEX, transformarÃ£o o sistema de um **motor de regras bÃ¡sico** para uma **plataforma enterprise de detecÃ§Ã£o de fraude** capaz de identificar fraudes sofisticadas e organizadas.

A implementaÃ§Ã£o estruturada em 3 fases permite **mÃ¡ximo impacto com mÃ­nimo risco**, comeÃ§ando pelos tipos de dados com melhor ROI (Tier 1) e expandindo gradualmente para casos de uso mais avanÃ§ados.

**Estimativa**: Com a implementaÃ§Ã£o completa, o RULEX serÃ¡ capaz de detectar **92% das fraudes** com apenas **8% de falsos positivos**, posicionando-o como uma **soluÃ§Ã£o enterprise de classe mundial**.
